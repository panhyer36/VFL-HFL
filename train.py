"""
VFL è¨“ç·´ä¸»è…³æœ¬ - å‚ç›´è¯é‚¦å­¸ç¿’ + FedAvg

**è¨“ç·´æµç¨‹**:
1. åˆå§‹åŒ– Server (å…¨å±€ Weather Model)
2. åˆå§‹åŒ– Clients (HFL Model + Fusion Model)
3. è¼‰å…¥ä¸¦é è™•ç†æ•¸æ“š (Weather + HFL)
4. è¯é‚¦å­¸ç¿’è¨“ç·´å¾ªç’° (FedAvg)
5. ä¿å­˜æ¨¡å‹å’Œå¯è¦–åŒ–çµæœ

**æ•¸æ“šæµ**:
- Server: ç®¡ç† Weather Modelï¼Œèšåˆæ¢¯åº¦
- Clients:
  * Weather æ•¸æ“š â†’ Weather Model â†’ Weather åµŒå…¥
  * HFL æ•¸æ“š â†’ HFL Model â†’ HFL åµŒå…¥
  * é›™æ–¹åµŒå…¥ â†’ Fusion Model â†’ é æ¸¬

**é€šè¨Šå„ªåŒ–**:
- éšæ®µ1: æ¯è¼ªéƒ½è¨“ç·´ Fusion + Weather
- éšæ®µ2: 4è¼ªè¨“ç·´ Fusionï¼Œ1è¼ªè¨“ç·´ Weather (ç¯€çœé€šè¨Š)
"""

import argparse
import os
import glob
import torch
import numpy as np
import pandas as pd
import pickle
from sklearn.preprocessing import StandardScaler
from torch.utils.data import TensorDataset, DataLoader
from dotenv import load_dotenv
import requests

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from config import load_config
from src.Server import VFLServer
from src.Client import VFLClient
from src.Personalizer import initialize_personalized_models

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()


def send_message(message):
    """
    ç™¼é€æ¶ˆæ¯åˆ° Webhook

    Args:
        message: è¦ç™¼é€çš„æ¶ˆæ¯å…§å®¹
    """
    if os.getenv('HOST_LINK') is None:
        return
    url = os.getenv('HOST_LINK')
    name = os.getenv('NAME')
    payload = {
        "name": name,
        "message": message
    }
    try:
        requests.post(url, json=payload)
    except Exception as e:
        print(f"Error sending message: {e}")

def load_weather_data(config):
    """
    è¼‰å…¥ Weather æ•¸æ“šä¸¦æ¨™æº–åŒ–

    Args:
        config: é…ç½®å°è±¡

    Returns:
        weather_data_scaled: æ¨™æº–åŒ–å¾Œçš„ Weather æ•¸æ“š
        weather_scaler: Weather æ¨™æº–åŒ–å™¨
    """
    print(f"\n{'=' * 70}")
    print("Loading Weather Data (Cloud)")
    print(f"{'=' * 70}")

    # è®€å– Weather CSV
    weather_csv_path = os.path.join(config.data_path, f"{config.weather_csv}.csv")
    weather_df = pd.read_csv(weather_csv_path)

    print(f"  - Weather raw data shape: {weather_df.shape}")
    print(f"  - Number of Weather features: {len(config.weather_features)}")

    # æå– Weather ç‰¹å¾µ
    weather_data_raw = weather_df[config.weather_features].values

    # æ¨™æº–åŒ–å™¨è·¯å¾‘
    weather_scaler_path = os.path.join(config.data_path, "weather_scaler.pkl")

    if os.path.exists(weather_scaler_path):
        # è¼‰å…¥å·²æœ‰çš„æ¨™æº–åŒ–å™¨
        with open(weather_scaler_path, 'rb') as f:
            weather_scaler = pickle.load(f)
        print(f"  V Weather scaler loaded")
    else:
        # å‰µå»ºæ–°çš„æ¨™æº–åŒ–å™¨
        weather_scaler = StandardScaler()
        weather_scaler.fit(weather_data_raw)
        with open(weather_scaler_path, 'wb') as f:
            pickle.dump(weather_scaler, f)
        print(f"  V Weather scaler created and saved")

    # æ¨™æº–åŒ–
    weather_data_scaled = weather_scaler.transform(weather_data_raw)
    print(f"  V Weather data normalized: {weather_data_scaled.shape}")

    return weather_data_scaled, weather_scaler


def create_weather_sequences(weather_data, seq_len, total_len):
    """
    å‰µå»º Weather æ™‚åºåºåˆ—

    Args:
        weather_data: Weather æ•¸æ“š (æ¨™æº–åŒ–å¾Œ)
        seq_len: åºåˆ—é•·åº¦
        total_len: éœ€è¦çš„åºåˆ—ç¸½æ•¸ (èˆ‡ HFL å°é½Š)

    Returns:
        weather_sequences: Weather åºåˆ—æ•¸çµ„
    """
    sequences = []
    for i in range(min(len(weather_data) - seq_len + 1, total_len)):
        sequences.append(weather_data[i:i + seq_len])
    return np.array(sequences)


def load_client_data(config, weather_sequences, client_csv_files):
    """
    è¼‰å…¥æ‰€æœ‰å®¢æˆ¶ç«¯çš„ HFL æ•¸æ“šä¸¦å‰µå»º DataLoader

    Args:
        config: é…ç½®å°è±¡
        weather_sequences: Weather åºåˆ—æ•¸çµ„
        client_csv_files: å®¢æˆ¶ç«¯ CSV æ–‡ä»¶è·¯å¾‘åˆ—è¡¨

    Returns:
        client_dataloaders: å­—å…¸ {client_name: {'train': loader, 'val': loader, 'train_size': int}}
        client_names: å®¢æˆ¶ç«¯åç¨±åˆ—è¡¨
        target_scaler: ç›®æ¨™è®Šé‡æ¨™æº–åŒ–å™¨
    """
    print(f"\n{'=' * 70}")
    print("Loading Client Data (Local)")
    print(f"{'=' * 70}")

    from src.DataLoader import SequenceCSVDataset

    client_dataloaders = {}
    client_names = []
    target_scaler = None
    hfl_scaler = None

    # åºåˆ—åƒæ•¸
    seq_length = config.input_length
    output_length = config.output_length
    batch_size = config.batch_size

    for idx, csv_file in enumerate(client_csv_files):
        client_name = os.path.basename(csv_file).replace('.csv', '')
        client_names.append(client_name)

        print(f"\nClient [{idx + 1}/{len(client_csv_files)}]: {client_name}")

        # è®€å–å®¢æˆ¶ç«¯æ•¸æ“š
        client_df = pd.read_csv(csv_file)

        # æª¢æŸ¥ç›®æ¨™è®Šé‡
        if config.target[0] not in client_df.columns:
            target_col = 'Consumption_Total'
        else:
            target_col = config.target[0]

        # æå–ç‰¹å¾µå’Œç›®æ¨™
        client_hfl_data = client_df[config.hfl_features].values
        client_target_data = client_df[target_col].values

        # æ¨™æº–åŒ–å™¨ (ç¬¬ä¸€å€‹å®¢æˆ¶ç«¯å‰µå»ºï¼Œå…¶é¤˜å…±ç”¨)
        if idx == 0:
            hfl_scaler = StandardScaler()
            hfl_scaler.fit(client_hfl_data)
            target_scaler = StandardScaler()
            target_scaler.fit(client_target_data.reshape(-1, 1))

            # ä¿å­˜æ¨™æº–åŒ–å™¨
            with open(os.path.join(config.data_path, 'hfl_scaler.pkl'), 'wb') as f:
                pickle.dump(hfl_scaler, f)
            with open(os.path.join(config.data_path, 'target_scaler.pkl'), 'wb') as f:
                pickle.dump(target_scaler, f)

        # æ¨™æº–åŒ–
        client_hfl_scaled = hfl_scaler.transform(client_hfl_data)
        client_target_scaled = target_scaler.transform(client_target_data.reshape(-1, 1)).flatten()

        # å°é½Šé•·åº¦
        min_len = min(len(weather_sequences), len(client_hfl_scaled), len(client_target_scaled))

        # å‰µå»ºåºåˆ—
        def create_sequences(weather, hfl, targets, seq_len):
            X_w, X_h, y = [], [], []
            for i in range(len(weather) - seq_len):
                X_w.append(weather[i])
                X_h.append(hfl[i:i + seq_len])
                y.append(targets[i + seq_len])
            return np.array(X_w), np.array(X_h), np.array(y)

        X_w, X_h, y = create_sequences(
            weather_sequences[:min_len],
            client_hfl_scaled[:min_len],
            client_target_scaled[:min_len],
            seq_length
        )

        # åˆ†å‰²æ•¸æ“šé›† (8:1:1)
        total = len(X_w)
        train_size = int(config.train_ratio * total)
        val_size = int(config.val_ratio * total)

        # è¨“ç·´é›†
        X_w_train = torch.FloatTensor(X_w[:train_size]).to(config.device)
        X_h_train = torch.FloatTensor(X_h[:train_size]).to(config.device)
        y_train = torch.FloatTensor(y[:train_size]).unsqueeze(1).to(config.device)

        # é©—è­‰é›†
        X_w_val = torch.FloatTensor(X_w[train_size:train_size + val_size]).to(config.device)
        X_h_val = torch.FloatTensor(X_h[train_size:train_size + val_size]).to(config.device)
        y_val = torch.FloatTensor(y[train_size:train_size + val_size]).unsqueeze(1).to(config.device)

        # å‰µå»º DataLoader
        train_dataset = TensorDataset(X_w_train, X_h_train, y_train)
        val_dataset = TensorDataset(X_w_val, X_h_val, y_val)

        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

        client_dataloaders[client_name] = {
            'train': train_loader,
            'val': val_loader,
            'train_size': len(train_dataset)
        }

        print(f"  V Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}")

    print(f"\nTotal loaded {len(client_dataloaders)} clients")
    return client_dataloaders, client_names, target_scaler


def train(args):
    """
    VFL è¨“ç·´ä¸»å‡½æ•¸

    Args:
        args: å‘½ä»¤è¡Œåƒæ•¸
    """
    print("\n" + "=" * 70)
    print("VFL Vertical Federated Learning Training - FedAvg")
    print("=" * 70)

    # === æ­¥é©Ÿ 1: è¼‰å…¥é…ç½® ===
    config = load_config(args.config)
    device = config.device

    print(f"\nConfiguration Summary:")
    print(f"  - Algorithm: {config.algorithm}")
    print(f"  - Total rounds: {config.K}")
    print(f"  - Number of clients: {config.num_users}")
    print(f"  - Batch size: {config.batch_size}")
    print(f"  - Learning rate: {config.beta}")
    print(f"  - Device: {device}")

    # === æ­¥é©Ÿ 2: è¼‰å…¥ Weather æ•¸æ“š ===
    weather_data_scaled, weather_scaler = load_weather_data(config)

    # === æ­¥é©Ÿ 3: è¼‰å…¥å®¢æˆ¶ç«¯æ•¸æ“š ===
    # ç²å–å®¢æˆ¶ç«¯ CSV æ–‡ä»¶
    csv_pattern = os.path.join(config.data_path, config.hfl_csv_pattern + ".csv")
    all_files = sorted(glob.glob(csv_pattern))

    # éæ¿¾å‡ºçœŸæ­£çš„ CSV æª”æ¡ˆ (æ’é™¤ .pkl.csv ç­‰)
    client_csv_files = [f for f in all_files if f.endswith('.csv') and not '.pkl' in f][:config.num_users]

    if not client_csv_files:
        raise FileNotFoundError(f"Client data not found: {csv_pattern}")

    print(f"\nFound {len(client_csv_files)} client files")

    # å‰µå»º Weather åºåˆ— (èˆ‡ç¬¬ä¸€å€‹å®¢æˆ¶ç«¯å°é½Š)
    # é€™è£¡å…ˆä¼°ç®—åºåˆ—æ•¸é‡
    first_client_df = pd.read_csv(client_csv_files[0])
    total_hfl_sequences = len(first_client_df) - config.input_length
    weather_sequences = create_weather_sequences(
        weather_data_scaled,
        config.input_length,
        total_hfl_sequences
    )

    print(f"\nWeather sequences created: {weather_sequences.shape}")

    # è¼‰å…¥æ‰€æœ‰å®¢æˆ¶ç«¯æ•¸æ“š
    client_dataloaders, client_names, target_scaler = load_client_data(
        config,
        weather_sequences,
        client_csv_files
    )

    # === æ­¥é©Ÿ 4: åˆå§‹åŒ– Per-FedAvg å€‹æ€§åŒ–æ¨¡å‹ (å¯é¸) ===
    client_hfl_models = {}
    if config.use_personalized_hfl and config.hfl_model_path:
        print(f"\n{'=' * 70}")
        print("Per-FedAvg Personalized HFL Model Initialization")
        print(f"{'=' * 70}")
        try:
            import torch
            from src.Model import TransformerModel
            from src.DataLoader import SequenceCSVDataset

            # æª¢æŸ¥ HFL å…¨å±€æ¨¡å‹æ˜¯å¦å­˜åœ¨
            if os.path.exists(config.hfl_model_path):
                print(f"  V Found HFL global model: {config.hfl_model_path}")

                # å‰µå»º HFL æ¨¡å‹æ¶æ§‹
                global_hfl_model = TransformerModel(
                    feature_dim=config.hfl_feature_dim,
                    d_model=config.hfl_d_model,
                    nhead=config.hfl_nhead,
                    num_layers=config.hfl_num_layers,
                    output_dim=config.hfl_output_dim,
                    max_seq_length=config.hfl_max_seq_length,
                    dropout=config.hfl_dropout
                ).to(device)

                # è¼‰å…¥å…¨å±€æ¨¡å‹æ¬Šé‡
                global_hfl_model.load_state_dict(torch.load(config.hfl_model_path, map_location=device))
                print(f"  V Successfully loaded HFL global model weights")

                # ç‚ºæ¯å€‹å®¢æˆ¶ç«¯é€²è¡Œå€‹æ€§åŒ–é©æ‡‰
                print(f"\n  Starting personalization adaptation for each client...")
                print(f"  Adaptation parameters: lr={config.adaptation_lr}, steps={config.personalization_steps}")
                print()

                for i, csv_file in enumerate(client_csv_files):
                    client_name = os.path.basename(csv_file).replace('.csv', '')
                    print(f"  [{i+1}/{len(client_csv_files)}] {client_name}:")

                    # è¼‰å…¥å®¢æˆ¶ç«¯æ•¸æ“šé›† (ç”¨æ–¼å€‹æ€§åŒ–)
                    try:
                        client_dataset = SequenceCSVDataset(
                            csv_path=os.path.dirname(csv_file),
                            csv_name=client_name,
                            input_len=config.input_length,
                            output_len=config.output_length,
                            features=config.hfl_features,
                            target=config.target,
                            save_path=os.path.dirname(csv_file),
                            train_ratio=config.train_ratio,
                            val_ratio=config.val_ratio,
                            split_type='time_based',
                            fit_scalers=False  # ä½¿ç”¨å·²ä¿å­˜çš„æ¨™æº–åŒ–å™¨
                        )

                        # ä½¿ç”¨ Personalizer é€²è¡Œå€‹æ€§åŒ–é©æ‡‰
                        from src.Personalizer import personalize_model_for_client
                        personalized_state = personalize_model_for_client(
                            global_model=global_hfl_model,
                            dataset=client_dataset,
                            config=config,
                            client_name=client_name
                        )

                        # ä¿å­˜å€‹æ€§åŒ–å¾Œçš„æ¨¡å‹æ¬Šé‡
                        client_hfl_models[client_name] = personalized_state

                    except Exception as e:
                        print(f"    âš  Personalization failed: {e}")
                        print(f"    -> Using global model weights")
                        client_hfl_models[client_name] = global_hfl_model.state_dict()

                print(f"\n  V Completed personalization adaptation for {len(client_hfl_models)} clients")
            else:
                print(f"  âš  HFL global model file not found: {config.hfl_model_path}")
                print(f"  -> Will use randomly initialized HFL model")
        except Exception as e:
            import traceback
            print(f"  âš  Failed to load/personalize HFL model: {e}")
            print(traceback.format_exc())
            print(f"  -> Will use randomly initialized HFL model")

    # === æ­¥é©Ÿ 5: åˆå§‹åŒ– Server å’Œ Clients ===
    print(f"\n{'=' * 70}")
    print("Initializing VFL Server and Clients")
    print(f"{'=' * 70}")

    # åˆå§‹åŒ– Server
    server = VFLServer(config, device)

    # åˆå§‹åŒ– Clients
    clients = {}
    for client_name in client_names:
        hfl_state_dict = client_hfl_models.get(client_name, None)
        client = VFLClient(
            client_id=client_name,
            config=config,
            device=device,
            hfl_model_state_dict=hfl_state_dict
        )
        clients[client_name] = client

    # === æ­¥é©Ÿ 6: è¯é‚¦å­¸ç¿’è¨“ç·´å¾ªç’° ===
    print(f"\n{'=' * 70}")
    print("Starting Federated Learning Training...")
    send_message("Starting Federated Learning Training...")
    print(f"{'=' * 70}")

    for round_idx in range(config.K):
        server.current_round = round_idx

        print(f"\n{'â”€' * 70}")
        print(f"Federated Learning Round [{round_idx + 1}/{config.K}]")
        print(f"{'â”€' * 70}")

        # ç¢ºå®šè¨“ç·´ç­–ç•¥
        train_weather = server.should_update_weather()

        if train_weather:
            print(f"  Training mode: Fusion Model + Weather Model âš¡")
        else:
            print(f"  Training mode: Fusion Model only (Save communication) ğŸ“¡")

        # å®¢æˆ¶ç«¯é¸æ“‡
        selected_clients = server.select_clients(client_names)
        print(f"\n  Selected clients: {selected_clients}")

        # === Split Learning å‰å‘å‚³æ’­: Server è¨ˆç®— Weather åµŒå…¥ ===
        print(f"\n  Server computing Weather embeddings:")

        # æ”¶é›†æ‰€æœ‰é¸ä¸­å®¢æˆ¶ç«¯çš„ Weather æ•¸æ“š
        client_weather_data = {}
        for client_name in selected_clients:
            train_loader = client_dataloaders[client_name]['train']
            val_loader = client_dataloaders[client_name]['val']

            # æå– Weather æ•¸æ“š (è¨“ç·´é›†)
            train_weather_batches = []
            for weather_batch, _, _ in train_loader:
                train_weather_batches.append(weather_batch)
            train_weather_data = torch.cat(train_weather_batches, dim=0).to(device)

            # æå– Weather æ•¸æ“š (é©—è­‰é›†)
            val_weather_batches = []
            for weather_batch, _, _ in val_loader:
                val_weather_batches.append(weather_batch)
            val_weather_data = torch.cat(val_weather_batches, dim=0).to(device)

            client_weather_data[client_name] = {
                'train': train_weather_data,
                'val': val_weather_data
            }

        # Server è¨ˆç®—åµŒå…¥å‘é‡
        client_weather_embeddings = {}
        for client_name in selected_clients:
            # è¨“ç·´é›†åµŒå…¥ (éœ€è¦æ¢¯åº¦)
            train_embeddings = server.compute_weather_embeddings(
                client_weather_data[client_name]['train'],
                requires_grad=train_weather
            )

            # é©—è­‰é›†åµŒå…¥ (ä¸éœ€è¦æ¢¯åº¦)
            val_embeddings = server.compute_weather_embeddings(
                client_weather_data[client_name]['val'],
                requires_grad=False
            )

            client_weather_embeddings[client_name] = {
                'train': train_embeddings,
                'val': val_embeddings
            }

            print(f"    V {client_name}: Train Embeddings {train_embeddings.shape}, Val Embeddings {val_embeddings.shape}")

        # === å®¢æˆ¶ç«¯æœ¬åœ°è¨“ç·´ (ä½¿ç”¨ Server ç™¼é€çš„åµŒå…¥) ===
        client_losses = []
        client_val_losses = []
        client_embedding_gradients = []
        client_sample_counts = []

        print(f"\n  Local training (Client side):")
        for client_name in selected_clients:
            client = clients[client_name]
            train_loader = client_dataloaders[client_name]['train']
            val_loader = client_dataloaders[client_name]['val']

            # æœ¬åœ°è¨“ç·´ (æ¥æ”¶ Server çš„åµŒå…¥)
            train_loss, embedding_grad, num_samples = client.local_train(
                train_loader,
                weather_embeddings=client_weather_embeddings[client_name]['train'],
                train_weather=train_weather
            )

            # æœ¬åœ°é©—è­‰
            val_loss = client.local_evaluate(
                val_loader,
                weather_embeddings=client_weather_embeddings[client_name]['val']
            )

            client_losses.append(train_loss)
            client_val_losses.append(val_loss)

            if train_weather and len(embedding_grad) > 0:
                client_embedding_gradients.append(embedding_grad)
                client_sample_counts.append(num_samples)

            print(f"    V {client_name}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}")

        # === Server èšåˆ Embedding æ¢¯åº¦ä¸¦æ›´æ–° Weather Model ===
        if train_weather and client_embedding_gradients:
            print(f"\n  Server aggregating Embedding gradients and updating Weather Model (Split Learning + FedAvg):")

            # ä½¿ç”¨ç¬¬ä¸€å€‹å®¢æˆ¶ç«¯çš„ Weather æ•¸æ“šé€²è¡Œåå‘å‚³æ’­ (æ‰€æœ‰å®¢æˆ¶ç«¯å…±äº«ç›¸åŒçš„ Weather æ•¸æ“š)
            representative_client = selected_clients[0]
            weather_data_for_backward = client_weather_data[representative_client]['train']

            server.update_weather_model_from_embeddings(
                weather_data_for_backward,
                client_embedding_gradients,
                client_sample_counts
            )
            print(f"    V Global Weather Model updated (Chain Rule)")
            print(f"    - Participating clients: {len(client_embedding_gradients)}")

        # å…¨å±€è©•ä¼°
        avg_train_loss = sum(client_losses) / len(client_losses)
        avg_val_loss = sum(client_val_losses) / len(client_val_losses)

        print(f"\n  [Round Results]")
        print(f"    Average train loss: {avg_train_loss:.6f}")
        print(f"    Average val loss: {avg_val_loss:.6f}")

        # æ—©åœæª¢æŸ¥
        should_stop = server.evaluate_global(avg_train_loss, avg_val_loss, selected_clients)
        if should_stop:
            print(f"\nEarly stopping triggered, training ended at round {round_idx + 1}")
            break

        # å®šæœŸè©•ä¼°
        if (round_idx + 1) % config.eval_interval == 0:
            print(f"\n  [Evaluation Summary - Round {round_idx + 1}]")
            print(f"    Best val loss: {server.best_val_loss:.6f}")
            print(f"    Early stopping counter: {server.patience_counter}/{config.early_stopping_patience}")

    # === æ­¥é©Ÿ 7: ä¿å­˜æ¨¡å‹ ===
    print(f"\n{'=' * 70}")
    print("Saving models...")
    print(f"{'=' * 70}")

    server.save_final_model()

    # ä¿å­˜å®¢æˆ¶ç«¯ Fusion Models
    for client_name, client in clients.items():
        fusion_path = os.path.join(
            config.model_save_path,
            f"{client_name}_fusion_model.pth"
        )
        client.save_fusion_model(fusion_path)
        print(f"  V {client_name} Fusion Model saved")

    # === æ­¥é©Ÿ 8: è¨“ç·´æ‘˜è¦ ===
    summary = server.get_training_summary()

    print(f"\n{'=' * 70}")
    print("Training completed!")
    send_message("Training completed!")
    print(f"{'=' * 70}")
    print(f"\nTraining Summary:")
    print(f"  - Total rounds: {summary['total_rounds']}")
    print(f"  - Weather Model updates: {summary['weather_updates']}")
    print(f"  - Actual communication saving: {summary['comm_saving_actual']:.1f}%")
    print(f"  - Best val loss: {summary['best_val_loss']:.6f}")
    print(f"  - Final train loss: {summary['final_train_loss']:.6f}")
    print(f"  - Final val loss: {summary['final_val_loss']:.6f}")

    print(f"\nModels saved to: {config.model_save_path}/")
    print("=" * 70)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='VFL Model Training')
    parser.add_argument('--config', default='config.yaml',
                        help='é…ç½®æ–‡ä»¶è·¯å¾‘ (default: config.yaml)')
    args = parser.parse_args()

    train(args)
