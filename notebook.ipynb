{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60cac029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型載入成功！\n"
     ]
    }
   ],
   "source": [
    "# 載入HFL_global_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from Model import TransformerModel\n",
    "device = torch.device(\"mps\")\n",
    "ssl_model_path = \"ssl_pretrain.pt\"\n",
    "hfl_model_path = \"HFL_global_model.pth\"\n",
    "HFL_Global_Model = TransformerModel(\n",
    "    feature_dim=14,\n",
    "    d_model=256,\n",
    "    nhead=8,\n",
    "    num_layers=4,\n",
    "    output_dim=1,\n",
    "    max_seq_length=100,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "SSL_Model = TransformerModel(\n",
    "    feature_dim=9,\n",
    "    d_model=256,\n",
    "    nhead=8,\n",
    "    num_layers=4,\n",
    "    output_dim=None,\n",
    "    max_seq_length=5000,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# 載入HFL模型\n",
    "HFL_Global_Model.load_state_dict(torch.load(hfl_model_path, map_location=device))\n",
    "\n",
    "# 載入SSL模型 - 需要從checkpoint中提取model_state_dict\n",
    "ssl_checkpoint = torch.load(ssl_model_path, map_location=device)\n",
    "if isinstance(ssl_checkpoint, dict) and 'model_state_dict' in ssl_checkpoint:\n",
    "    SSL_Model.load_state_dict(ssl_checkpoint['model_state_dict'])\n",
    "else:\n",
    "    SSL_Model.load_state_dict(ssl_checkpoint)\n",
    "\n",
    "print(\"模型載入成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "lepnw6uq1hk",
   "source": "# 使用 Trainer 載入 Dataset\nimport glob\nimport os\nfrom config import load_config\nfrom DataLoader import SequenceCSVDataset\nfrom Trainer import FederatedTrainer\n\n# 載入配置（如果沒有 config.yaml，需要先創建一個簡單的配置對象）\ntry:\n    config = load_config('config.yaml')\nexcept:\n    # 如果沒有配置文件，創建一個簡單的配置對象\n    class SimpleConfig:\n        def __init__(self):\n            self.data_path = \"./data\"  # 請根據實際路徑修改\n            self.input_length = 96\n            self.output_length = 1\n            self.features = ['feature1', 'feature2']  # 請根據實際特徵修改\n            self.target = 'Power_Demand'\n            self.batch_size = 32\n            self.device = device\n    \n    config = SimpleConfig()\n\n# 載入數據集（以第一個客戶端為例）\ncsv_pattern = os.path.join(config.data_path, \"*.csv\")\ncsv_files = sorted(glob.glob(csv_pattern))\n\nif csv_files:\n    # 載入第一個客戶端的數據\n    csv_file = csv_files[0]\n    csv_name = os.path.splitext(os.path.basename(csv_file))[0]\n    \n    print(f\"載入客戶端數據: {csv_name}\")\n    \n    # 創建數據集對象\n    dataset = SequenceCSVDataset(\n        csv_path=config.data_path,\n        csv_name=csv_name,\n        input_len=config.input_length,\n        output_len=config.output_length,\n        features=config.features,\n        target=config.target,\n        save_path=config.data_path,\n        train_ratio=0.8,\n        val_ratio=0.1,\n        split_type='time_based',\n        fit_scalers=False  # 使用已保存的標準化器\n    )\n    \n    # 使用 Trainer 分割數據集\n    trainer = FederatedTrainer(HFL_Global_Model, config, device)\n    train_dataset, val_dataset, test_dataset = trainer.split_dataset(dataset)\n    \n    # 創建數據加載器\n    train_loader, val_loader, test_loader = trainer.create_data_loaders(\n        train_dataset, val_dataset, test_dataset\n    )\n    \n    print(f\"\\n✓ 數據載入成功！\")\n    print(f\"  - 訓練集大小: {len(train_dataset)} 樣本\")\n    print(f\"  - 驗證集大小: {len(val_dataset)} 樣本\")\n    print(f\"  - 測試集大小: {len(test_dataset)} 樣本\")\n    print(f\"  - 批次大小: {config.batch_size}\")\n    \n    # 查看一個批次的數據形狀\n    for inputs, targets in train_loader:\n        print(f\"\\n數據形狀:\")\n        print(f\"  - 輸入: {inputs.shape}\")\n        print(f\"  - 目標: {targets.shape}\")\n        break\nelse:\n    print(f\"錯誤: 在 {config.data_path} 目錄下沒有找到任何 CSV 文件\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "jodenz93nwc",
   "source": "# 使用 Personalizer 獲取每個客戶端的個性化模型\nfrom Personalizer import initialize_personalized_models, save_personalized_models\n\nprint(\"=\" * 70)\nprint(\"Per-FedAvg 個性化模型初始化\")\nprint(\"=\" * 70)\n\n# 方法 1: 使用配置文件進行個性化\n# 確保 config 中包含必要的參數\nif not hasattr(config, 'adaptation_lr'):\n    config.adaptation_lr = 0.01  # 個性化適應學習率\nif not hasattr(config, 'personalization_steps'):\n    config.personalization_steps = 10  # 個性化適應步數\nif not hasattr(config, 'model_save_path'):\n    config.model_save_path = \"./models\"  # 模型保存路徑\n\n# 指定全局模型路徑（Per-FedAvg 訓練好的模型）\nglobal_model_path = hfl_model_path  # 使用前面載入的 HFL 模型路徑\n\ntry:\n    # 初始化所有客戶端的個性化模型\n    print(f\"\\n使用全局模型: {global_model_path}\")\n    print(f\"個性化參數:\")\n    print(f\"  - 適應學習率: {config.adaptation_lr}\")\n    print(f\"  - 適應步數: {config.personalization_steps}\")\n    print(f\"  - 設備: {config.device}\")\n    \n    # 獲取所有客戶端的個性化模型狀態字典\n    client_models = initialize_personalized_models(config, global_model_path)\n    \n    print(f\"\\n✓ 成功獲取 {len(client_models)} 個客戶端的個性化模型\")\n    print(f\"\\n客戶端列表:\")\n    for idx, client_name in enumerate(client_models.keys(), 1):\n        print(f\"  {idx}. {client_name}\")\n    \n    # 可選：保存個性化模型到磁盤\n    save_dir = \"personalized_models\"\n    save_personalized_models(client_models, save_dir)\n    \n    # 示範：如何使用特定客戶端的個性化模型\n    print(f\"\\n{'=' * 70}\")\n    print(\"使用範例：載入特定客戶端的個性化模型\")\n    print(\"=\" * 70)\n    \n    if client_models:\n        # 獲取第一個客戶端的名稱\n        first_client = list(client_models.keys())[0]\n        \n        print(f\"\\n示範：載入客戶端 '{first_client}' 的個性化模型\")\n        \n        # 創建新的模型實例\n        personalized_model_client_1 = TransformerModel(\n            feature_dim=config.feature_dim if hasattr(config, 'feature_dim') else 14,\n            d_model=256,\n            nhead=8,\n            num_layers=4,\n            output_dim=None,  # VFL 場景：不需要輸出層\n            max_seq_length=100,\n            dropout=0.1\n        ).to(device)\n        \n        # 載入個性化後的權重\n        personalized_model_client_1.load_state_dict(client_models[first_client])\n        personalized_model_client_1.eval()\n        \n        print(f\"✓ 成功載入客戶端 '{first_client}' 的個性化模型\")\n        print(f\"\\n模型已準備好用於 VFL 訓練！\")\n        \n        # 示範：使用個性化模型進行前向傳播（不含輸出投影）\n        print(f\"\\n{'=' * 70}\")\n        print(\"VFL 場景示範：使用個性化模型生成嵌入向量\")\n        print(\"=\" * 70)\n        \n        # 模擬兩個參與方的數據\n        batch_size = 8\n        seq_length = 96\n        \n        # Party A 的數據（客戶端 1）\n        x_party_a = torch.randn(batch_size, seq_length, 14).to(device)\n        \n        with torch.no_grad():\n            # 使用個性化模型生成嵌入（不含輸出投影）\n            embedding_a = personalized_model_client_1.forward_embedding(x_party_a)\n        \n        print(f\"\\n✓ Party A 嵌入向量形狀: {embedding_a.shape}\")\n        print(f\"  - 批次大小: {embedding_a.shape[0]}\")\n        print(f\"  - 嵌入維度: {embedding_a.shape[1]}\")\n        print(f\"\\n這個嵌入向量可以發送到 Server 進行融合預測！\")\n        print(f\"原始數據 ({x_party_a.shape}) 保持在本地，保護隱私。\")\n        \nexcept FileNotFoundError as e:\n    print(f\"\\n❌ 錯誤: {e}\")\n    print(\"請確認全局模型路徑是否正確\")\nexcept Exception as e:\n    print(f\"\\n❌ 發生錯誤: {e}\")\n    print(\"請檢查配置和數據路徑是否正確\")\n\nprint(f\"\\n{'=' * 70}\")\nprint(\"個性化模型初始化完成\")\nprint(\"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "t67xhdxjs4n",
   "source": "# ============================================================================\n# VFL 場景：載入 Weather (雲端) 和 HFL (本地) 的 Dataset\n# ============================================================================\n\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport pickle\n\nprint(\"=\" * 80)\nprint(\"VFL 數據載入：Weather (雲端) + HFL (本地)\")\nprint(\"=\" * 80)\n\n# === 配置參數 ===\ndata_path = \"./data\"\nweather_csv = \"Weather.csv\"\nhfl_csv = \"processed/Consumer_01.csv\"  # 使用第一個消費者作為示例\n\n# HFL 特徵（本地客戶端）\nhfl_features = [\n    'AC1', 'AC2', 'AC3', 'AC4', \n    'Dish washer', 'Washing Machine', 'Dryer', 'Water heater',\n    'TV', 'Microwave', 'Kettle', 'Lighting', 'Refrigerator', \n    'Consumption_Total'\n]\n\n# Weather 特徵（雲端）\nweather_features = [\n    'TemperatureC', 'DewpointC', 'PressurehPa', \n    'WindSpeedKMH', 'WindSpeedGustKMH', 'Humidity',\n    'HourlyPrecipMM', 'dailyrainMM', 'SolarRadiationWatts_m2'\n]\n\n# 目標變量\ntarget = 'Power_Demand'\n\n# 序列參數\nseq_length = 96\nbatch_size = 32\n\nprint(f\"\\n【數據配置】\")\nprint(f\"  - Weather 特徵數: {len(weather_features)}\")\nprint(f\"  - HFL 特徵數: {len(hfl_features)}\")\nprint(f\"  - 序列長度: {seq_length}\")\nprint(f\"  - 批次大小: {batch_size}\")\n\n# ============================================================================\n# 步驟 1: 載入 Weather 數據（雲端）\n# ============================================================================\nprint(f\"\\n【步驟 1】載入 Weather 數據（雲端）\")\n\nweather_df = pd.read_csv(f\"{data_path}/{weather_csv}\")\nprint(f\"  ✓ Weather 原始數據: {weather_df.shape}\")\nprint(f\"  - 可用特徵: {list(weather_df.columns)}\")\n\n# 確保有 datetime 欄位\nif 'datetime' in weather_df.columns:\n    weather_df['datetime'] = pd.to_datetime(weather_df['datetime'])\n    weather_df.set_index('datetime', inplace=True)\n    weather_df.sort_index(inplace=True)\n\n# 提取 Weather 特徵\nweather_data = weather_df[weather_features].values\nprint(f\"  ✓ Weather 特徵矩陣: {weather_data.shape}\")\n\n# === Weather 標準化器（在雲端創建）===\nweather_scaler = StandardScaler()\nweather_data_scaled = weather_scaler.fit_transform(weather_data)\nprint(f\"  ✓ Weather 數據已標準化\")\nprint(f\"    - 均值: {weather_scaler.mean_[:3]}...\")\nprint(f\"    - 標準差: {weather_scaler.scale_[:3]}...\")\n\n# 保存 Weather 標準化器（用於後續推理）\nscaler_path = f\"{data_path}/weather_scaler.pkl\"\nwith open(scaler_path, 'wb') as f:\n    pickle.dump(weather_scaler, f)\nprint(f\"  ✓ Weather 標準化器已保存: {scaler_path}\")\n\n# ============================================================================\n# 步驟 2: 載入 HFL 數據（本地客戶端）\n# ============================================================================\nprint(f\"\\n【步驟 2】載入 HFL 數據（本地客戶端）\")\n\nhfl_df = pd.read_csv(f\"{data_path}/{hfl_csv}\")\nprint(f\"  ✓ HFL 原始數據: {hfl_df.shape}\")\n\n# 檢查是否有 Power_Demand 目標\nif target not in hfl_df.columns:\n    print(f\"  ⚠ 警告: 沒有找到 '{target}' 欄位，使用 'Consumption_Total' 作為目標\")\n    target = 'Consumption_Total'\n\n# 提取 HFL 特徵\nhfl_data = hfl_df[hfl_features].values\ntarget_data = hfl_df[target].values\nprint(f\"  ✓ HFL 特徵矩陣: {hfl_data.shape}\")\nprint(f\"  ✓ 目標變量: {target_data.shape}\")\n\n# === HFL 標準化器（在本地創建）===\nhfl_scaler = StandardScaler()\nhfl_data_scaled = hfl_scaler.fit_transform(hfl_data)\nprint(f\"  ✓ HFL 數據已標準化\")\n\ntarget_scaler = StandardScaler()\ntarget_data_scaled = target_scaler.fit_transform(target_data.reshape(-1, 1)).flatten()\nprint(f\"  ✓ 目標變量已標準化\")\n\n# 保存 HFL 標準化器\nhfl_scaler_path = f\"{data_path}/hfl_scaler.pkl\"\ntarget_scaler_path = f\"{data_path}/target_scaler.pkl\"\nwith open(hfl_scaler_path, 'wb') as f:\n    pickle.dump(hfl_scaler, f)\nwith open(target_scaler_path, 'wb') as f:\n    pickle.dump(target_scaler, f)\nprint(f\"  ✓ HFL 標準化器已保存: {hfl_scaler_path}\")\nprint(f\"  ✓ 目標標準化器已保存: {target_scaler_path}\")\n\n# ============================================================================\n# 步驟 3: 對齊時間並創建序列數據\n# ============================================================================\nprint(f\"\\n【步驟 3】對齊時間並創建序列數據\")\n\n# 確保兩個數據集長度一致\nmin_len = min(len(weather_data_scaled), len(hfl_data_scaled), len(target_data_scaled))\nweather_data_scaled = weather_data_scaled[:min_len]\nhfl_data_scaled = hfl_data_scaled[:min_len]\ntarget_data_scaled = target_data_scaled[:min_len]\n\nprint(f\"  ✓ 對齊後數據長度: {min_len}\")\n\n# 創建序列數據集\ndef create_sequences(weather, hfl, targets, seq_len):\n    \"\"\"創建時序序列數據\"\"\"\n    X_weather, X_hfl, y = [], [], []\n    \n    for i in range(len(weather) - seq_len):\n        X_weather.append(weather[i:i+seq_len])\n        X_hfl.append(hfl[i:i+seq_len])\n        y.append(targets[i+seq_len])  # 預測下一個時間點\n    \n    return np.array(X_weather), np.array(X_hfl), np.array(y)\n\nX_weather_seq, X_hfl_seq, y_seq = create_sequences(\n    weather_data_scaled, \n    hfl_data_scaled, \n    target_data_scaled,\n    seq_length\n)\n\nprint(f\"  ✓ Weather 序列: {X_weather_seq.shape}\")\nprint(f\"  ✓ HFL 序列: {X_hfl_seq.shape}\")\nprint(f\"  ✓ 目標序列: {y_seq.shape}\")\n\n# ============================================================================\n# 步驟 4: 分割訓練/驗證/測試集（時間順序）\n# ============================================================================\nprint(f\"\\n【步驟 4】分割訓練/驗證/測試集（8:1:1）\")\n\ntotal_samples = len(X_weather_seq)\ntrain_size = int(0.8 * total_samples)\nval_size = int(0.1 * total_samples)\n\n# 時間順序分割\nX_weather_train = X_weather_seq[:train_size]\nX_hfl_train = X_hfl_seq[:train_size]\ny_train = y_seq[:train_size]\n\nX_weather_val = X_weather_seq[train_size:train_size+val_size]\nX_hfl_val = X_hfl_seq[train_size:train_size+val_size]\ny_val = y_seq[train_size:train_size+val_size]\n\nX_weather_test = X_weather_seq[train_size+val_size:]\nX_hfl_test = X_hfl_seq[train_size+val_size:]\ny_test = y_seq[train_size+val_size:]\n\nprint(f\"  ✓ 訓練集: {len(X_weather_train)} 樣本\")\nprint(f\"  ✓ 驗證集: {len(X_weather_val)} 樣本\")\nprint(f\"  ✓ 測試集: {len(X_weather_test)} 樣本\")\n\n# ============================================================================\n# 步驟 5: 創建 PyTorch DataLoader\n# ============================================================================\nprint(f\"\\n【步驟 5】創建 PyTorch DataLoader\")\n\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# 轉換為 PyTorch Tensor\nX_weather_train_t = torch.FloatTensor(X_weather_train).to(device)\nX_hfl_train_t = torch.FloatTensor(X_hfl_train).to(device)\ny_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n\nX_weather_val_t = torch.FloatTensor(X_weather_val).to(device)\nX_hfl_val_t = torch.FloatTensor(X_hfl_val).to(device)\ny_val_t = torch.FloatTensor(y_val).unsqueeze(1).to(device)\n\nX_weather_test_t = torch.FloatTensor(X_weather_test).to(device)\nX_hfl_test_t = torch.FloatTensor(X_hfl_test).to(device)\ny_test_t = torch.FloatTensor(y_test).unsqueeze(1).to(device)\n\n# 創建 Dataset\ntrain_dataset_vfl = TensorDataset(X_weather_train_t, X_hfl_train_t, y_train_t)\nval_dataset_vfl = TensorDataset(X_weather_val_t, X_hfl_val_t, y_val_t)\ntest_dataset_vfl = TensorDataset(X_weather_test_t, X_hfl_test_t, y_test_t)\n\n# 創建 DataLoader\ntrain_loader_vfl = DataLoader(train_dataset_vfl, batch_size=batch_size, shuffle=True)\nval_loader_vfl = DataLoader(val_dataset_vfl, batch_size=batch_size, shuffle=False)\ntest_loader_vfl = DataLoader(test_dataset_vfl, batch_size=batch_size, shuffle=False)\n\nprint(f\"  ✓ 訓練 DataLoader: {len(train_loader_vfl)} 批次\")\nprint(f\"  ✓ 驗證 DataLoader: {len(val_loader_vfl)} 批次\")\nprint(f\"  ✓ 測試 DataLoader: {len(test_loader_vfl)} 批次\")\n\n# ============================================================================\n# 數據載入完成\n# ============================================================================\nprint(f\"\\n{'=' * 80}\")\nprint(\"✓ VFL 數據載入完成！\")\nprint(f\"{'=' * 80}\")\nprint(f\"\\n數據摘要:\")\nprint(f\"  【雲端 - Weather】\")\nprint(f\"    - 特徵維度: {len(weather_features)}\")\nprint(f\"    - 訓練樣本: {X_weather_train.shape}\")\nprint(f\"  【本地 - HFL】\")\nprint(f\"    - 特徵維度: {len(hfl_features)}\")\nprint(f\"    - 訓練樣本: {X_hfl_train.shape}\")\nprint(f\"  【目標】\")\nprint(f\"    - 變量: {target}\")\nprint(f\"    - 訓練樣本: {y_train.shape}\")\nprint(f\"\\n下一步：建立 Weather Model（雲端）和 Fusion Model（伺服器）\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bkb7cu5skf",
   "source": "# ============================================================================\n# VFL 訓練：Fusion Model（本地）與 Weather Model（雲端）的訓練\n# ============================================================================\n\nfrom Model import TransformerModel, FusionModel\nfrom tqdm import tqdm\n\nprint(\"=\" * 80)\nprint(\"VFL 訓練：Fusion Model (本地) ↔ Weather Model (雲端)\")\nprint(\"=\" * 80)\n\n# ============================================================================\n# 步驟 1: 初始化模型\n# ============================================================================\nprint(f\"\\n【步驟 1】初始化模型\")\n\n# === Weather Model（雲端，可訓練）===\nweather_model = TransformerModel(\n    feature_dim=len(weather_features),  # 9個氣象特徵\n    d_model=256,\n    nhead=8,\n    num_layers=4,\n    output_dim=None,  # 不需要輸出層，只產生嵌入\n    max_seq_length=seq_length,\n    dropout=0.1\n).to(device)\n\nprint(f\"  ✓ Weather Model 已初始化（雲端，可訓練）\")\nprint(f\"    - 輸入維度: {len(weather_features)}\")\nprint(f\"    - 嵌入維度: 256\")\nprint(f\"    - 可訓練參數: {sum(p.numel() for p in weather_model.parameters()):,}\")\n\n# === HFL Model（本地，凍結不訓練）===\n# 使用個性化後的模型（從前面的 Cell 獲得）\nif 'client_models' in locals() and len(client_models) > 0:\n    first_client = list(client_models.keys())[0]\n    hfl_model = TransformerModel(\n        feature_dim=len(hfl_features),  # 14個 HFL 特徵\n        d_model=256,\n        nhead=8,\n        num_layers=4,\n        output_dim=None,  # 不需要輸出層\n        max_seq_length=seq_length,\n        dropout=0.1\n    ).to(device)\n    hfl_model.load_state_dict(client_models[first_client])\n    print(f\"  ✓ HFL Model 已載入（本地，來自個性化模型 '{first_client}'）\")\nelse:\n    # 如果沒有個性化模型，使用 HFL 全局模型\n    hfl_model = TransformerModel(\n        feature_dim=len(hfl_features),\n        d_model=256,\n        nhead=8,\n        num_layers=4,\n        output_dim=None,\n        max_seq_length=seq_length,\n        dropout=0.1\n    ).to(device)\n    # 嘗試載入 HFL 全局模型權重\n    try:\n        # 需要創建一個臨時模型來載入權重，因為 output_dim 不同\n        temp_model = TransformerModel(\n            feature_dim=14,\n            d_model=256,\n            nhead=8,\n            num_layers=4,\n            output_dim=1,  # 臨時使用\n            max_seq_length=100,\n            dropout=0.1\n        ).to(device)\n        temp_model.load_state_dict(torch.load(hfl_model_path, map_location=device))\n        \n        # 只複製非輸出層的權重\n        hfl_state_dict = {}\n        for key, value in temp_model.state_dict().items():\n            if 'output_proj' not in key:\n                hfl_state_dict[key] = value\n        \n        hfl_model.load_state_dict(hfl_state_dict, strict=False)\n        print(f\"  ✓ HFL Model 已載入（本地，來自全局模型）\")\n    except:\n        print(f\"  ⚠ HFL Model 使用隨機初始化（無法載入預訓練權重）\")\n\n# 凍結 HFL Model（不訓練）\nfor param in hfl_model.parameters():\n    param.requires_grad = False\nhfl_model.eval()\nprint(f\"  ✓ HFL Model 已凍結（不參與訓練）\")\n\n# === Fusion Model（本地客戶端，可訓練）===\nfusion_model = FusionModel(\n    embedding_dim_party_a=256,  # Weather 嵌入維度\n    embedding_dim_party_b=256,  # HFL 嵌入維度\n    hidden_dim=256,\n    output_dim=1,  # 預測電力需求\n    dropout=0.1\n).to(device)\n\nprint(f\"  ✓ Fusion Model 已初始化（本地客戶端，可訓練）\")\nprint(f\"    - 可訓練參數: {sum(p.numel() for p in fusion_model.parameters()):,}\")\n\n# ============================================================================\n# 步驟 2: 設置優化器和損失函數\n# ============================================================================\nprint(f\"\\n【步驟 2】設置優化器和損失函數\")\n\n# Weather Model 優化器（雲端）\nweather_optimizer = torch.optim.Adam(\n    weather_model.parameters(),\n    lr=0.001,\n    weight_decay=1e-4\n)\n\n# Fusion Model 優化器（本地）\nfusion_optimizer = torch.optim.Adam(\n    fusion_model.parameters(),\n    lr=0.001,\n    weight_decay=1e-4\n)\n\n# 損失函數\ncriterion = nn.MSELoss()\n\nprint(f\"  ✓ 優化器已設置\")\nprint(f\"    - Weather Model LR: 0.001 (雲端)\")\nprint(f\"    - Fusion Model LR: 0.001 (本地)\")\n\n# ============================================================================\n# 步驟 3: 訓練配置\n# ============================================================================\nnum_epochs = 50\nprint_every = 5\n\nprint(f\"\\n【步驟 3】訓練配置\")\nprint(f\"  - 訓練輪數: {num_epochs}\")\nprint(f\"  - 訓練策略: 本地訓練 Fusion Model，雲端訓練 Weather Model\")\nprint(f\"  - HFL Model: 凍結（不訓練）\")\n\nprint(f\"\\n【VFL 架構說明】\")\nprint(f\"  ┌─────────────────────────────────────────────────────────┐\")\nprint(f\"  │                    雲端 (Cloud)                         │\")\nprint(f\"  │  ┌───────────────────────────────────────────┐          │\")\nprint(f\"  │  │  Weather Model (可訓練)                    │          │\")\nprint(f\"  │  │  - 輸入: Weather 數據 (9 特徵)             │          │\")\nprint(f\"  │  │  - 輸出: Weather 嵌入向量 (256 維)        │          │\")\nprint(f\"  │  └──────────────┬────────────────────────────┘          │\")\nprint(f\"  └─────────────────┼─────────────────────────────────────────┘\")\nprint(f\"                    │ Weather 嵌入向量 (256 維)\")\nprint(f\"                    │ 傳送到本地客戶端\")\nprint(f\"                    ▼\")\nprint(f\"  ┌─────────────────────────────────────────────────────────┐\")\nprint(f\"  │                 本地客戶端 (Client)                      │\")\nprint(f\"  │  ┌───────────────────────────────────────────┐          │\")\nprint(f\"  │  │  HFL Model (凍結，不訓練)                  │          │\")\nprint(f\"  │  │  - 輸入: HFL 本地數據 (14 特徵)            │          │\")\nprint(f\"  │  │  - 輸出: HFL 嵌入向量 (256 維)            │          │\")\nprint(f\"  │  └──────────────┬────────────────────────────┘          │\")\nprint(f\"  │                 │ HFL 嵌入 (256)                         │\")\nprint(f\"  │                 │                                        │\")\nprint(f\"  │  ┌──────────────▼────────────────────────────┐          │\")\nprint(f\"  │  │  Fusion Model (本地，可訓練)               │          │\")\nprint(f\"  │  │  - 輸入: Weather 嵌入 + HFL 嵌入          │          │\")\nprint(f\"  │  │  - 輸出: Power Demand 預測                │          │\")\nprint(f\"  │  └──────────────┬────────────────────────────┘          │\")\nprint(f\"  └─────────────────┼─────────────────────────────────────────┘\")\nprint(f\"                    │ Weather 嵌入的梯度\")\nprint(f\"                    │ 傳回雲端\")\nprint(f\"                    ▼\")\nprint(f\"            更新 Weather Model\")\n\n# 記錄訓練歷史\ntrain_losses = []\nval_losses = []\n\n# ============================================================================\n# 步驟 4: 訓練循環\n# ============================================================================\nprint(f\"\\n{'=' * 80}\")\nprint(\"開始訓練...\")\nprint(\"=\" * 80)\n\nfor epoch in range(num_epochs):\n    # ========================================================================\n    # 本地訓練階段\n    # ========================================================================\n    fusion_model.train()\n    weather_model.train()\n    \n    epoch_train_loss = 0.0\n    \n    for weather_batch, hfl_batch, targets in train_loader_vfl:\n        # === 本地前向傳播 ===\n        # 步驟 1: 雲端 Weather Model 生成嵌入（需要梯度）\n        weather_embedding = weather_model.forward_embedding(weather_batch)\n        \n        # 步驟 2: 本地 HFL Model 生成嵌入（凍結，不需要梯度）\n        with torch.no_grad():\n            hfl_embedding = hfl_model.forward_embedding(hfl_batch)\n        \n        # === 本地 Fusion Model 訓練 ===\n        # 步驟 3: 本地 Fusion Model 預測\n        fusion_optimizer.zero_grad()\n        weather_optimizer.zero_grad()\n        \n        predictions = fusion_model(weather_embedding, hfl_embedding)\n        loss = criterion(predictions, targets)\n        \n        # === 反向傳播 ===\n        # 步驟 4: 計算梯度（會傳播到 Weather Model）\n        loss.backward()\n        \n        # 步驟 5: 更新本地 Fusion Model\n        fusion_optimizer.step()\n        \n        # 步驟 6: 更新雲端 Weather Model（通過梯度）\n        weather_optimizer.step()\n        \n        epoch_train_loss += loss.item()\n    \n    # ========================================================================\n    # 驗證階段\n    # ========================================================================\n    weather_model.eval()\n    fusion_model.eval()\n    \n    val_loss = 0.0\n    with torch.no_grad():\n        for weather_batch, hfl_batch, targets in val_loader_vfl:\n            weather_embedding = weather_model.forward_embedding(weather_batch)\n            hfl_embedding = hfl_model.forward_embedding(hfl_batch)\n            predictions = fusion_model(weather_embedding, hfl_embedding)\n            loss = criterion(predictions, targets)\n            val_loss += loss.item()\n    \n    # 計算平均損失\n    avg_train_loss = epoch_train_loss / len(train_loader_vfl)\n    avg_val_loss = val_loss / len(val_loader_vfl)\n    \n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n    \n    # 打印進度\n    if (epoch + 1) % print_every == 0 or epoch == 0:\n        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n        print(f\"  - Train Loss: {avg_train_loss:.6f}\")\n        print(f\"  - Val Loss: {avg_val_loss:.6f}\")\n\nprint(f\"\\n{'=' * 80}\")\nprint(\"✓ 訓練完成！\")\nprint(\"=\" * 80)\n\n# ============================================================================\n# 步驟 5: 評估模型\n# ============================================================================\nprint(f\"\\n【步驟 5】評估模型\")\n\nweather_model.eval()\nfusion_model.eval()\n\ntest_loss = 0.0\nall_predictions = []\nall_targets = []\n\nwith torch.no_grad():\n    for weather_batch, hfl_batch, targets in test_loader_vfl:\n        # 雲端: Weather 嵌入\n        weather_embedding = weather_model.forward_embedding(weather_batch)\n        # 本地: HFL 嵌入\n        hfl_embedding = hfl_model.forward_embedding(hfl_batch)\n        # 本地: Fusion 預測\n        predictions = fusion_model(weather_embedding, hfl_embedding)\n        \n        loss = criterion(predictions, targets)\n        test_loss += loss.item()\n        \n        all_predictions.extend(predictions.cpu().numpy())\n        all_targets.extend(targets.cpu().numpy())\n\navg_test_loss = test_loss / len(test_loader_vfl)\nall_predictions = np.array(all_predictions)\nall_targets = np.array(all_targets)\n\n# 計算評估指標\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nmse = mean_squared_error(all_targets, all_predictions)\nmae = mean_absolute_error(all_targets, all_predictions)\nrmse = np.sqrt(mse)\nr2 = r2_score(all_targets, all_predictions)\n\nprint(f\"\\n測試集性能:\")\nprint(f\"  - MSE: {mse:.6f}\")\nprint(f\"  - MAE: {mae:.6f}\")\nprint(f\"  - RMSE: {rmse:.6f}\")\nprint(f\"  - R²: {r2:.6f}\")\n\n# ============================================================================\n# 步驟 6: 可視化結果\n# ============================================================================\nprint(f\"\\n【步驟 6】可視化結果\")\n\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# 訓練損失曲線\naxes[0, 0].plot(train_losses, label='Train Loss', color='blue')\naxes[0, 0].plot(val_losses, label='Val Loss', color='orange')\naxes[0, 0].set_xlabel('Epoch')\naxes[0, 0].set_ylabel('Loss')\naxes[0, 0].set_title('Training and Validation Loss')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# 預測 vs 實際（散點圖）\naxes[0, 1].scatter(all_targets, all_predictions, alpha=0.5, s=10)\naxes[0, 1].plot([all_targets.min(), all_targets.max()], \n                [all_targets.min(), all_targets.max()], \n                'r--', lw=2, label='Perfect Prediction')\naxes[0, 1].set_xlabel('Actual')\naxes[0, 1].set_ylabel('Predicted')\naxes[0, 1].set_title(f'Predictions vs Actual (R²={r2:.4f})')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# 時間序列預測（前 200 個樣本）\nsample_size = min(200, len(all_targets))\naxes[1, 0].plot(all_targets[:sample_size], label='Actual', color='blue', linewidth=2)\naxes[1, 0].plot(all_predictions[:sample_size], label='Predicted', color='red', linewidth=1, alpha=0.7)\naxes[1, 0].set_xlabel('Time Step')\naxes[1, 0].set_ylabel('Power Demand')\naxes[1, 0].set_title('Time Series Prediction (First 200 samples)')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# 誤差分佈\nerrors = all_predictions.flatten() - all_targets.flatten()\naxes[1, 1].hist(errors, bins=50, alpha=0.7, color='green', edgecolor='black')\naxes[1, 1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\naxes[1, 1].set_xlabel('Prediction Error')\naxes[1, 1].set_ylabel('Frequency')\naxes[1, 1].set_title(f'Error Distribution (MAE={mae:.4f})')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('vfl_training_results.png', dpi=150, bbox_inches='tight')\nprint(f\"  ✓ 可視化圖表已保存: vfl_training_results.png\")\n\nplt.show()\n\nprint(f\"\\n{'=' * 80}\")\nprint(\"VFL 訓練和評估完成！\")\nprint(\"=\" * 80)\nprint(f\"\\n模型摘要:\")\nprint(f\"  【Weather Model（雲端）】\")\nprint(f\"    - 狀態: 已訓練\")\nprint(f\"    - 位置: 雲端\")\nprint(f\"    - 參數: {sum(p.numel() for p in weather_model.parameters()):,}\")\nprint(f\"  【HFL Model（本地）】\")\nprint(f\"    - 狀態: 凍結（未訓練）\")\nprint(f\"    - 位置: 本地客戶端\")\nprint(f\"    - 參數: {sum(p.numel() for p in hfl_model.parameters()):,}\")\nprint(f\"  【Fusion Model（本地）】\")\nprint(f\"    - 狀態: 已訓練\")\nprint(f\"    - 位置: 本地客戶端（每個客戶端自有）\")\nprint(f\"    - 參數: {sum(p.numel() for p in fusion_model.parameters()):,}\")\nprint(f\"\\n訓練策略:\")\nprint(f\"  ✓ Fusion Model 在本地訓練，融合 Weather 和 HFL 嵌入\")\nprint(f\"  ✓ Weather Model 在雲端訓練，通過梯度反向傳播更新\")\nprint(f\"  ✓ HFL Model 保持凍結，保留個性化特徵\")\nprint(f\"  ✓ 隱私保護機制:\")\nprint(f\"    - Weather 數據存於雲端，只傳送嵌入向量到本地\")\nprint(f\"    - HFL 原始數據不離開本地\")\nprint(f\"    - Fusion Model 在本地，預測結果不外傳\")\nprint(f\"    - 只有 Weather 嵌入的梯度傳回雲端\")\nprint(f\"\\n資料流向:\")\nprint(f\"  前向: 雲端(Weather嵌入) → 本地(融合+預測)\")\nprint(f\"  反向: 本地(梯度) → 雲端(更新Weather Model)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}